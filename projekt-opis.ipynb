{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea209eb-1cc6-4ea7-a860-59d25902f2f9",
   "metadata": {},
   "source": [
    "## 1. Importy i ustawienie seedu losowości\n",
    "\n",
    "W pierwszym bloku importujemy potrzebne biblioteki:\n",
    "- `torch` - biblioteka PyTorch do obliczeń tensorowych\n",
    "- `tenseal` – biblioteka do szyfrowania homomorficznego\n",
    "- `pandas` – obsługa danych\n",
    "- `random, np.random, torch.random` – generowanie liczb losowych\n",
    "- `time` – mierzenie czasu wykonania operacji\n",
    "- `StandardScaler` – normalizacja danych\n",
    "- `numpy` – operacje matematyczne\n",
    "- `matplotlib.pyplot` – wizualizacja danych\n",
    "- `datasets` i `train_test_split` – dostęp do gotowych zbiorów danych i ich podział na zbiór treningowy i testowy\n",
    "\n",
    "Następnie ustawiamy seed losowości w trzech różnych bibliotekach (torch, random, numpy). To zapewnia powtarzalność wyników – np. przy każdym uruchomieniu programu generowane liczby losowe będą takie same. To istotne w analizach naukowych lub przy testowaniu modeli ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c179c-2644-4ffb-8912-7a3dbf36e436",
   "metadata": {},
   "source": [
    "## 2. Wczytanie zbioru danych i podział na zbiór treningowy i testowy\n",
    "\n",
    "W tym bloku wczytujemy gotowy zbiór danych dotyczących raka piersi z biblioteki `scikit-learn`. Zmienna `X` to dane wejściowe, kolumny takie jak np. „mean radius”, „mean texture”, itp. Zmienna `y_np` to etykiety klas: 0 oznacza nowotwór złośliwy, 1 – łagodny. Następnie dzielimy dane na zbiór treningowy oraz testowy w proporcjach: 67% - zbiór treningowy, 33% - zbiór testowy. `Random state = 42` zapewnia powtarzalność tego podziału."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba8f12-d425-447c-9624-e85a5f382838",
   "metadata": {},
   "source": [
    "## 3. Konwersja danych do tensorów PyTorch\n",
    "\n",
    "Dane wejściowe `X_train_np` i `X_test_np` są konwertowane do tensorów typu `float32`. Etykiety `y_train_np` i `y_test_np` również są konwertowane, ale dodatkowo za pomocą `unsqueeze` zmieniamy ich kształt z `[n]` na `[n,1]`, w celu dopasowania ich do sieci neuronowych, wymagają kolumnowej formy danych wyjściowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9dacc-b75c-459e-9c9d-f663f1821e8c",
   "metadata": {},
   "source": [
    "## 4. Standaryzacja danych\n",
    "\n",
    "Dla każdej cechy w danych obliczana jest średnia `mean` i odchylenie standardowe `std` w zbiorze treningowym. Dla cech, gdzie odchylenie standardowe wynosi 0, zostaje ono zastąpione 1.0, aby uniknąć dzielenia przez zero. Dane są następnie standaryzowane; `x_test` jest skalowane tymi samymi wartościami `mean` i `std`, co `x_train`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b8684-4f62-490b-8542-b01d84ccda65",
   "metadata": {},
   "source": [
    "Podsumowując dane z klasyfikacji raka piersi zostały pobrane, podzielone, skonwertowane do tensorów PyTorch i odpowiednio przeskalowane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a8dd8-d2fe-41dd-bcd9-dc553a7ce2df",
   "metadata": {},
   "source": [
    "## 5. Wizualizacja danych treningowych\n",
    "\n",
    "Tworzymy wykres rozrzutu punktów treningowych, bazujący na pierwszych dwóch cechach. Kolor każdego punktu odpowiada klasie (0 lub 1), więc wizualnie możemy sprawdzić, czy dane klas są łatwe do rozdzielenia. Cechy są wcześniej standaryzowane, więc mają średnią 0 i podobną skalę. Wykres pomaga zrozumieć rozkład danych oraz ich separowalność.\n",
    "\n",
    "#### Obserwacje na podstawie wykresu:\n",
    "\n",
    "- Separacja klas nie jest wyraźna: nie widać jednej prostej linii, która łatwo oddzieliłaby klasę 0 od 1 tylko na podstawie tych dwóch cech. Części klas nachodzą na siebie, co może prowadzić do trudności w klasyfikacji przy prostym modelu\n",
    "- Gęstość punktów: największe skupiska punktów znajdują się wokół `(0, 0)` – czyli w pobliżu średniej wartości cech. Można zauważyć, że dane są dość mocno skoncentrowane w tym obszarze, a rzadziej występują na krańcach.\n",
    "- Potencjalna korelacja: widoczna jest lekka skośność (pozytywna korelacja) między cechami – im większa cecha 1, tym częściej cecha 2 również wzrasta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9956d6-86ca-477a-9193-496706766907",
   "metadata": {},
   "source": [
    "## 6. Definicja modelu regresji logistycznej w PyTorch\n",
    "\n",
    "Tworzymy klasę `LR`, czyli prosty model regresji logistycznej. Składa się z jednej warstwy liniowej `Linear` przyjmującej `n_features` i zwracającej wartość prawdopodobieństwa. Na wyjściu stosujemy funkcję sigmoidalną, by uzyskać wynik w przedziale (0, 1) w ramach klasycznej regresji logistycznej binarnej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0ee3b-a2ed-45d3-83c3-1dd4bcbe2dc9",
   "metadata": {},
   "source": [
    "## 7. Inicjalizacja modelu, optymalizatora i funkcji straty\n",
    "\n",
    "Tworzymy instancję modelu, przekazując liczbę cech wejściowych, optymalizator: `SGD` (stochastyczny spadek gradientu) z learning rate = 1, funkcję straty: `BCELoss` do klasyfikacji binarnej. Ustawiamy liczbę epok treingu na 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9ada4-e06a-4b0c-b491-812fae80c029",
   "metadata": {},
   "source": [
    "## 8. Funkcja treningu modelu i jego trenowanie.\n",
    "\n",
    "Pętla treningowa wykonuje się przez wcześniej ustaloną liczbę epok (zmienna `EPOCHS`). W każdej epoce:\n",
    "- liczymy forward pass\n",
    "- obliczamy stratę\n",
    "- backpropagation\n",
    "- aktualizujemy wagi\n",
    "\n",
    "Na koniec wypisujemy stratę dla każdej epoki. Następnie trenujemy model na danych treningowych przy użyciu wcześniej zdefiniowanej funkcji `train`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5b483a-85b2-4d47-a340-aa669c918b7e",
   "metadata": {},
   "source": [
    "## 9. Pomiar dokładności na danych testowych\n",
    "\n",
    "Funkcja `accuracy` sprawdza, czy model dobrze klasyfikuje dane. Wyniki wyjściowe `out` traktowane są jako przewidywania klasy 1, jeśli są w odległości < 0.5 od 1. Następnie obliczamy  średnią liczbę poprawnych przewidywań. Na koniec wypisujemy dokładność na zbiorze testowym.\n",
    "\n",
    "#### Obserwacje wyników\n",
    "\n",
    "- Strata systematycznie spada z każdą epoką, co oznacza, że model uczy się poprawnie.\n",
    "- Spadek jest największy na początku, między epoką 1 a 2, a potem się stabilizuje.\n",
    "- Ostateczna wartość straty (≈ 0.13) sugeruje, że model dobrze dopasował się do danych treningowych.\n",
    "- Model osiągnął bardzo wysoką trafność klasyfikacji: 97.87%. To wskazuje na brak under- i overfittingu. Wynik jest bardzo dobry jak na prosty model logistyczny działający tylko na standaryzowanych danych bez rozszerzeń cech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d41b23-9d2e-495b-8c1c-a52ffb7a388e",
   "metadata": {},
   "source": [
    "## 10. Definicja modelu EncryptedLR_eval\n",
    "\n",
    "Tworzmy klasę `EncryptedLR_eval`, która odwzorowuje działanie modelu regresji logistycznej w środowisku zaszyfrowanym. Metoda `encrypt(context)` zamienia wagi i bias na zaszyfrowane wektory CKKS. Funkcja `forward()` działa na zaszyfrowanych danych wejściowych przy pomocy operacji dopuszczalnych w szyfrowaniu homomorficznym; `decrypt()` umożliwia odszyfrowanie wag i biasów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c30898-4961-45a2-b2c7-3f6f2cd73640",
   "metadata": {},
   "source": [
    "## 11. Inicjalizacja modelu i konfiguracja kontekstu szyfrowania CKKS oraz szyfrowanie danych testowych\n",
    "\n",
    "Tworzymy instancję `EncryptedLR_eval` na podstawie wytrenowanego modelu. Konfigurujemy kontekst CKKS z parametrami:\n",
    "\n",
    "- `poly_mod_degree = 4096` – kompromis między wydajnością a dokładnością.\n",
    "- `coeff_mod_bit_sizes = [40, 20, 40]`– rozmiary poziomów w drzewie resztowym.\n",
    "- `global_scale = 2²⁰` – zapewnia dobrą precyzję i stabilność operacji.\n",
    "\n",
    "Galois keys są wymagane do operacji takich jak rotacje lub mnożenia przez skalary.\n",
    "\n",
    "Dane testowe są szyfrowane w formie wektorów CKKS – jeden wektor na jedną próbkę. Pomiar czasu pokazuje koszt szyfrowania, który może być znaczny dla dużych zbiorów danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011b0d1-ff77-4fac-8acf-529992762872",
   "metadata": {},
   "source": [
    "## 12. Funkcja ewaluacji zaszyfrowanego modelu uruchomienie jej i porównanie z klasyczną\n",
    "\n",
    "Funkcja wykonuje forward pass na zaszyfrowanych danych testowych. Po każdej predykcji następuje odszyfrowanie i klasyfikacja przy użyciu funkcji sigmoidalnej. Porównuje się wynik z prawdziwą etykietą, i zlicza poprawne trafienia. Zwracamy łączną dokładność oraz czas ewaluacji.\n",
    "\n",
    "Uruchamiamy ewaluację na zaszyfrowanym zbiorze danych i porównujemy wynik z klasyczną dokładnością `plain_accuracy`. Jeśli przypadkiem trafność zaszyfrowana byłaby wyższa (co jest możliwe np. przez zaokrąglenia), kod to zauważy i wypisze komunikat.\n",
    "\n",
    "#### Obserwacje wyników:\n",
    "\n",
    "- Proces szyfrowania danych testowych był błyskawiczny, czas poniżej 1s.\n",
    "- Ewaluacja odbyła się bardzo szybko – tylko 1 sekunda dla 188 próbek.\n",
    "- rafność (accuracy) modelu na zaszyfrowanych danych wynosi 88.83%. Jest to nieco niższy wynik niż dla danych jawnych, jednak wciąż przyzwoity szczególnie jak na obliczenia szyfrowane.\n",
    "- Różnica trafności to ~9.04 p.p., czyli zaszyfrowany model klasyfikuje poprawnie średnio 9% mniej przypadków niż model działający na danych jawnych. To akceptowalna cena za zachowanie prywatności, zwłaszcza w zastosowaniach takich jak: ochrona danych medycznych czy klasyfikacja danych finansowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2568fc4-8af7-46b7-8f63-6d2f474ccac5",
   "metadata": {},
   "source": [
    "## 13. Bezpieczna ewaluacja z użyciem TenSEAL – ograniczenia i zalecenia\n",
    "\n",
    "Biblioteka TenSEAL (tak jak wiele innych bibliotek FHE) używa obiektów takich jak `CKKSVector`, które posiadają wewnętrzny stan napisany w języku C++. Obiekty te nie są bezpieczne w środowiskach wielowątkowych, co oznacza, że próby równoległego przetwarzania z użyciem współdzielonej pamięci (np. threading) mogą prowadzić do błędów, awarii lub uszkodzenia danych.\n",
    "\n",
    "Dodatkowo, obiekty te nie mogą być serializowane (pickle), co uniemożliwia ich przekazywanie do procesów potomnych w klasycznym modelu multiprocessing.\n",
    "\n",
    "Zamiast współdzielenia danych zaszyfrowanych między wątkami lub procesami, należy zastosować równoległość opartą na procesach (process-based parallelism), gdzie każdy proces tworzy swój własny kontekst TenSEAL i szyfruje dane niezależnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19422f33-4e4e-47e3-9c93-2c812bf3a370",
   "metadata": {},
   "source": [
    "## 14. Porównanie sekwencyjnego i równoległego szyfrowania oraz ewaluacja zaszyfrowanego modelu\n",
    "\n",
    "Skrypt wykonuje wielokrotne porównanie dwóch podejść: sekwencyjnego szyfrowania i ewaluacji oraz równoległego z użyciem multiprocessingu przy wykorzystaniu lokalnych kontekstów TenSEAL.\n",
    "\n",
    "Importujemy bibliotekę potrzebną multiprocessingu, funkcje `encrypt_chunk` i `evaluate_chunk`, które obsługują szyfrowanie i ewaluację w workerach. Zapewniamy kompatybilność z bibliotekami FHE (np. TenSEAL), które nie są bezpieczne przy domyślnej metodzie fork.\n",
    "\n",
    "Następnie ustalamy parametry i inicjalizujemy zmienne:\n",
    "\n",
    "- `num_procs`: liczba procesów równoległych.\n",
    "\n",
    "- `num_runs`: liczba powtórzeń eksperymentu, by uśrednić wyniki.\n",
    "\n",
    "Inicjalizujemy listy do zapisu czasów i trafności w obu wariantach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60935d-e175-47a3-a737-2a822739f3dc",
   "metadata": {},
   "source": [
    "## 15. Konfiguracja kontekstu TenSEAL i modelu\n",
    "\n",
    "Tworzymy kontekst CKKS z wybranymi parametrami. Model `EncryptedLR_eval` jest inicjalizowany na podstawie wcześniej wytrenowanego modelu PyTorch. Wszystkie obiekty są serializowane, aby mogły być bezpiecznie przesłane do workerów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b7d7f-02bc-403c-8d01-85322845edfd",
   "metadata": {},
   "source": [
    "## 16. Przygotowanie danych, szyfrowanie sekwencyjne i równoległe\n",
    "\n",
    "Dane testowe są konwertowane do formatu NumPy, aby mogły być dzielone na kawałki i przesyłane do procesów. \n",
    "##### Sekwencyjne szyfrowanie: \n",
    "Każdy wiersz danych testowych jest zamieniany na `CKKSVector`, zaszyfrowany i zserializowany. Proces ten odbywa się jeden po drugim. \n",
    "##### Równoległe szyfrowanie:\n",
    "Dane testowe są dzielone na `num_procs` części. Każdy worker szyfruje fragment danych własnym lokalnym kontekstem. Wszystkie zaszyfrowane fragmenty są zbierane w jedną listę."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661e5c6-b7ca-48d4-89fe-a02f11a0c95c",
   "metadata": {},
   "source": [
    "## 17. Ewaluacja zaszyfrowanych danych\n",
    "\n",
    "##### Sekwencyjna:\n",
    "Każdy zaszyfrowany wektor jest deserializowany i podawany na wejście modelu. Wynik jest odszyfrowywany, przekształcany przez funkcję sigmoidalną i porównywany z prawdziwą etykietą.\n",
    "\n",
    "##### Równoległa:\n",
    "Zaszyfrowane dane są dzielone i przekazywane do workerów razem z etykietami. Każdy worker wykonuje ewaluację lokalnie i zwraca wyniki do głównego procesu.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69619b-b1b6-42da-b825-c4fb849e569a",
   "metadata": {},
   "source": [
    "## 18. Zebranie wyników, zapisanie i porównanie metryk, wizualizacja\n",
    "\n",
    "Czas i trafność są zapisywane w odpowiednich listach, obliczane są przyspieszenie czasowe i różnice trafności. Tworzone są dwa wykresy porównujące: czas całkowity w każdej próbie, trafność modelu w każdej próbie.\n",
    "\n",
    "##### Obserwacje:\n",
    "\n",
    "We wszystkich przypadkach trafność modelu jest identyczna lub różni się nieznacznie, co świadczy o stabilności algorytmu przy równoległym podejściu.\n",
    "\n",
    "W każdym z trzech przebiegów podejście sekwencyjne było znacznie szybsze niż równoległe. Czas działania rośnie dla obu metod wraz z kolejnymi uruchomieniami, ale dla podejścia równoległego wzrost ten jest znacznie bardziej stromy (np. ~13s → ~20s). Podejście sekwencyjne oscyluje w granicach 3 sekund i rośnie minimalnie.\n",
    "\n",
    "Równoległe szyfrowanie i ewaluacja nie przynoszą korzyści czasowych, wręcz są mniej wydajne w obecnej konfiguracji i skali. Jednak w przypadku większych zbiorów danych podejście równoległe ma większy wpływ na czas obliczeń."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8e6aa-b55d-4244-a703-f87520150a88",
   "metadata": {},
   "source": [
    "## 19. Testy z wykorzystaniem sklearn\n",
    "\n",
    "W tej wersji projektu zastąpiono model regresji logistycznej zaimplementowany w PyTorch jego odpowiednikiem z biblioteki `Scikit-Learn`. Zachowany został ten sam zbiór danych `Breast Cancer Dataset`, jednak teraz przygotowano go w formacie kompatybilnym z sklearn, co umożliwia bezpośrednie wykorzystanie funkcji takich jak `LogisticRegression`, `train_test_split`, `StandardScaler`, itd. Jednocześnie testowano ewaluację na danych zaszyfrowanych homomorficznie (FHE, CKKS – TenSEAL), zarówno w wersji sekwencyjnej, jak i równoległej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6bb338-8c55-4e32-b338-04ef6b40d06e",
   "metadata": {},
   "source": [
    "## 20. Podsumowanie danych\n",
    "\n",
    "Zastosowano podział 2:1 (trening:test), czyli ~67% danych do treningu, ~33% do testu. Dane zawierają 54 cechy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a73711-12c2-49ab-852e-e0138d07d7ca",
   "metadata": {},
   "source": [
    "## 21. Obserwacje wynikow z sklearn\n",
    "\n",
    "- Równoległość przyniosła realne przyspieszenie, czas działania skrócił się blisko czterokrotnie dzięki wykorzystaniu multiprocessing. To duża różnica względem wcześniejszych wyników z PyTorch, gdzie równoległość była wolniejsza.\n",
    "- Zarówno wersja sekwencyjna, jak i równoległa osiągały dokładnie 63.97% trafności na zbiorze testowym. Oznacza to, że szyfrowanie i sposób przetwarzania nie miały negatywnego wpływu na skuteczność predykcji.\n",
    "- Trafność niższa niż w wersji nieszyfrowanej. Wcześniej model na danych jawnych osiągał 76.52% – różnica ok. 12.5 punktu procentowego.\n",
    "\n",
    "\n",
    "Równoległa ewaluacja homomorficzna nie wpływa negatywnie na skuteczność klasyfikacji. Brak rozrzutu sugeruje wysoką powtarzalność działania modelu i stabilność FHE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b897a8e-35ca-4df3-84f1-1ff40e173b4b",
   "metadata": {},
   "source": [
    "## 22. PyTorch vs Sklearn\n",
    "\n",
    "##### Zalety PyTorch:\n",
    "- Bardziej elastyczny, możesz dokładnie kontrolować architekturę (np. sigmoid, warstwy).\n",
    "- Lepsza jakość modelu przy mniejszym zbiorze (prawie 98% accuracy).\n",
    "- Niższy czas ewaluacji zaszyfrowanej, ale na znacznie mniejszych danych.\n",
    "\n",
    "#####  Zalety Scikit-learn:\n",
    "\n",
    "- Szybszy i prostszy w użyciu dla klasycznych problemów.\n",
    "- Umożliwia użycie pełnego zbioru i regularizacji bez dodatkowego kodu.\n",
    "- Świetnie współpracuje z równoległą ewaluacją FHE (speedup 3.6x przy stałej accuracy).\n",
    "\n",
    "##### Kiedy wybrać Sklearn a kiedy PyTorch:\n",
    "\n",
    "- Pełna kontrola nad modelem, niestandardowa architektura - PyTorch\n",
    "- Trenować duży zbiór i porównać wiele modeli - Sklearn\n",
    "- Łączyć klasyczne ML z deep learningiem - PyTorch\n",
    "- Użyć gotowej regresji z automatycznym skalowaniem i regularyzacją - Sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
